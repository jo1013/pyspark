{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edcad221",
   "metadata": {},
   "source": [
    "## Pyspark DB 연결 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84afc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "import findspark\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "import MySQLdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9102ce7",
   "metadata": {},
   "source": [
    "# ----------------TEST------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class abc : \n",
    "    \n",
    "    def __init__(self, host, dbname,jdbcPort,user,password,query):\n",
    "            \n",
    "        self.host = host\n",
    "        self.dbname = dbname\n",
    "        self.jdbcPort = jdbcPort\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.query = query\n",
    "        \n",
    "    def spark_sql_to_pandas(self,host,jdbcPort,dbname,user,password,query):\n",
    "        findspark.add_packages('mysql:mysql-connector-java:8.0.25') # mysql connecter\n",
    "        conf = SparkConf().setAll([('spark.driver.extraClassPath',\n",
    "                            '/usr/share/java/mysql-connector-java-8.0.25.jar')])  # jar path추가.\n",
    "        sc = SparkContext(appName=\"TestPySparkJDBC\", conf=conf)\n",
    "        sqlContext = SQLContext(sc)        \n",
    "        jdbc_url = \"jdbc:mysql://{0}:{1}/{2}?user={3}&password={4}\".format(self.host,self.jdbcPort,self.dbname,self.user,self.password)\n",
    "        df = sqlContext.read.format('jdbc').options(driver='com.mysql.jdbc.Driver', url=jdbc_url, dbtable=query).load().toPandas()\n",
    "        return df\n",
    "   \n",
    "    def create_table(self,host,jdbcPort,dbname,user,password):\n",
    "        engine = create_engine(\"mysql+mysqldb://{0}:{1}@{2}:{3}/{4}\".format(self.user, self.password,self.host,self.jdbcPort,self.dbname),encoding='utf-8')\n",
    "        self.conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbbd8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f269d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "defg = abc(host,dbname,jdbcPort,user,password,query)\n",
    "\n",
    "Pet_DataFrame = defg.spark_sql_to_pandas(host,dbname,jdbcPort,user,password,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86e947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pet_kinds = list(Pet_DataFrame[['breed']]['breed'])\n",
    "temp = {}\n",
    "temp2 = {}\n",
    "for i in Pet_kinds:\n",
    "    if i in temp: \n",
    "        temp[i] = temp[i] + 1\n",
    "    else:\n",
    "        temp[i] = 1 #없을 때\n",
    "Pet_names = list(Pet_DataFrame[['name']]['name'])\n",
    "for i in Pet_names:\n",
    "    if i in temp2: \n",
    "        temp2[i] = temp2[i] + 1\n",
    "    else:\n",
    "        temp2[i] = 1 #없을 때\n",
    "        \n",
    "data = pd.DataFrame(list(temp.items()),columns = ['pet_kind', 'count'])\n",
    "\n",
    "data2 = pd.DataFrame(list(temp2.items()),columns = ['pet_name', 'n_count'])\n",
    "\n",
    "final_df = pd.merge(data,data2, how ='outer',left_index= True, right_index= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬용\n",
    "host = \"172.23.0.1\"\n",
    "dbname = \"testdb\"\n",
    "jdbcPort = 3306\n",
    "user = \"root\"\n",
    "password = \"root\"\n",
    "query = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = abc(host,dbname,jdbcPort,user,password,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = temp.create_table(host,dbname,jdbcPort,user,password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ffebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = final_df.fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82842f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055c3de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df.to_sql(name='defg', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b4046",
   "metadata": {},
   "source": [
    "# ----------------TEST------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b6f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.add_packages('mysql:mysql-connector-java:8.0.25') # mysql connecter\n",
    "conf = SparkConf().setAll([('spark.driver.extraClassPath',\n",
    "                            '/usr/share/java/mysql-connector-java-8.0.25.jar')])  # jar path추가.\n",
    "sc = SparkContext(appName=\"TestPySparkJDBC\", conf=conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "conf = SparkConf().setAll([('spark.driver.extraClassPath',\n",
    "                        '/usr/share/java/mysql-connector-java-8.0.25.jar')])  # jar path추가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49642c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname = \"localhost\" #local주소 컨테이너내에서 환경이기 때문에 ip주소가 필요\n",
    "dbname = \"sims\"\n",
    "jdbcPort = 3307\n",
    "username = \"smt_csl_prd\"\n",
    "password = \"WpYrPRCwoPTx5NcQcucE\"\n",
    "jdbc_url = \"jdbc:mysql://{0}:{1}/{2}?user={3}&password={4}\".format(hostname,jdbcPort,dbname,username,password)\n",
    "query = '(select * from pet) AS t'\n",
    "df = sqlContext.read.format('jdbc').options(driver='com.mysql.jdbc.Driver', url=jdbc_url, dbtable=query).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba7985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pet_DataFrame = df.toPandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2487741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pet_DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1d9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pet_kinds = list(Pet_DataFrame[['breed']]['breed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {}\n",
    "temp2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b989fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in Pet_kinds:\n",
    "    if i in temp: \n",
    "        temp[i] = temp[i] + 1\n",
    "    else:\n",
    "        temp[i] = 1 #없을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae9b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pet_names = list(Pet_DataFrame[['name']]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3197ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Pet_names:\n",
    "    if i in temp2: \n",
    "        temp2[i] = temp2[i] + 1\n",
    "    else:\n",
    "        temp2[i] = 1 #없을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed253f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(temp.items()),columns = ['pet_kind', 'count'])\n",
    "\n",
    "data2 = pd.DataFrame(list(temp2.items()),columns = ['pet_name', 'n_count'])\n",
    "\n",
    "final_df = pd.merge(data,data2, how ='outer',left_index= True, right_index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810febd4",
   "metadata": {},
   "source": [
    "## 내부 로컬 db (insert할 db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+mysqldb://root:\"+\"root\"+\"@172.23.0.1:3306/testdb\", encoding='utf-8')\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c29103",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_sql(name='abc', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c280f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname = \"172.23.0.1\" #local주소 컨테이너내에서 환경이기 때문에 ip주소가 필요\n",
    "dbname = \"testdb\"\n",
    "jdbcPort = 3306\n",
    "username = \"root\"\n",
    "password = \"root\"\n",
    "jdbc_url = \"jdbc:mysql://{0}:{1}/{2}?user={3}&password={4}\".format(hostname,jdbcPort,dbname,username,password)\n",
    " \n",
    "query = '(select * from testest) AS t'\n",
    "df1 = sqlContext.read.format('jdbc').options(driver='com.mysql.jdbc.Driver', url=jdbc_url, dbtable=query).load()\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9c5ec",
   "metadata": {},
   "source": [
    "# -------------test ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad3c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import batch_test as t\n",
    "import pandas as pd\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "import findspark\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "import MySQLdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = t.file_batch(query = '(select * from pet) AS t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = base.execute('(select * from pet) AS t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff9867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
