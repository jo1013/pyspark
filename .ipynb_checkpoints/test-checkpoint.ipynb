{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1dab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "conf = pyspark.SparkConf()\\\n",
    "        .setAppName(\"spark-sql\")\\\n",
    "        .set(\"spark.driver.extraClassPath\", \"./data/mysql-connector-java-8.0.17/mysql-connector-java-8.0.17.jar\")\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "from pyspark.sql import SQLContext\n",
    "sqlCtx = SQLContext(sc)\n",
    "spark = sqlCtx.sparkSession\n",
    "\n",
    "\n",
    "\n",
    "sql_url = \"localhost\"\n",
    "user = \"root\"\n",
    "password = \"root\"\n",
    "database = \"testdb\"\n",
    "table = \"testtest\"\n",
    "\n",
    "\n",
    "jdbc = spark.read.format(\"jdbc\")\\\n",
    "                .option(\"driver\", \"com.mysql.jdbc.Driver\")\\\n",
    "                .option(\"url\", \"jdbc:mysql://{}:3306/{}?serverTimezone=Asia/Seoul \".format(sql_url, database))\\\n",
    "                .option(\"user\", user)\\\n",
    "                .option(\"password\", password)\\\n",
    "                .option(\"dbtable\", table)\\\n",
    "                .load()\n",
    "jdbc.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1bf4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAll([('spark.driver.extraClassPath',\n",
    "                            '/Users/go/Downloads/mysql-connector-java-5.1.47-bin.jar')])  # jar path추가.\n",
    "\n",
    "sc = SparkContext(appName=\"TestPySparkJDBC\", conf=conf)\n",
    "sqlContext = SQLContext(sc)\n",
    " \n",
    "hostname = \"localhost\"\n",
    "dbname = \"testdb\"\n",
    "jdbcPort = 3306\n",
    "username = \"root\"\n",
    "password = \"root\"\n",
    "jdbc_url = \"jdbc:mysql://{0}:{1}/{2}?user={3}&password={4}&useSSL=false&allowPublicKeyRetrieval=true\".format(hostname,jdbcPort,dbname,username,password)\n",
    " \n",
    "query = '(select 1) AS t'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003cbb9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = sqlContext.read.format('jdbc').options(driver='com.mysql.jdbc.Driver', url=jdbc_url, dbtable=query).load()\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff09419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "if __name__ == '__main__':\n",
    "    scSpark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"reading csv\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '12_19_stt.csv'\n",
    "sdfData = scSpark.read.csv(data_file, header=True, sep=\",\", encoding='euc-kr').cache()\n",
    "print('Total Records = {}'.format(sdfData.count()))\n",
    "sdfData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8da052",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sdfData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7876e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914beba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.jars\", \"/usr/share/java/mysql-connector-java-8.0.22.jar\") \\\n",
    "    .master(\"local\").appName(\"PySpark_MySQL_test\").getOrCreate()\n",
    "\n",
    "wine_df = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:mysql://localhost:3306/testDB\") \\\n",
    "    .option(\"driver\", \"com.mysql.jdbc.Driver\").option(\"dbtable\", \"testtest\") \\\n",
    "    .option(\"user\", \"root\").option(\"password\", \"root\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1a8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
